---
title: "In Sync with the Brain: Modeling Visual Binding through Neural Synchrony"
collection: publications
category: thesis
permalink: /publication/thesis
excerpt: 'This thesis tests the long-standing idea that neural synchrony helps the brain bind visual features into objects. By developing neural network models that incorporate synchrony in different ways, it shows that temporal coordination improves object representations, robustness, and human-like behavior. Analyses of primate IT recordings further suggest that synchrony carries meaningful information beyond firing rates. These findings support synchrony as a useful mechanism for visual perception and for designing more brain-like AI models.'
date: 2025-07-15
venue: 'University of Toulouse'
paperurl: 'https://theses.hal.science/tel-05351777/document'
citation: '<strong>Muzellec, S.</strong> (2025). In Sync with the Brain : Modeling Visual Binding through Neural Synchrony.Neuroscience. Universit√© de Toulouse.'
featured: true
header:
    teaser: "thesis.png"
---

This thesis seeks empirical evidence for temporal coordination --also called neural synchrony-- as a viable mechanism to perform visual binding. While neural synchrony, characterized by simultaneous rhythmic neuronal activity, is a prominent theory in neuroscience for integrating visual features into coherent object representations, its functional role remains challenging to validate experimentally. To address this gap, we leverage computational models to investigate synchrony's role in visual processing. Specifically, we explore methods for inducing neural synchrony in artificial neural networks and evaluate the computational advantages it confers. We utilize complex-valued representations, given their biologically plausible incorporation of temporal dynamics within standard ANNs, where synchrony is naturally represented by similarity in the phase values between neurons. This thesis introduces three distinct models that induce synchrony through different mechanisms. The first model, KomplexNet, embeds Kuramoto synchronization dynamics within a convolutional neural network, allowing explicit phase alignment between units to drive feature grouping. The second model, GASPnet, introduces a global top-down attentional signal that modulates synchrony selectively across the network, demonstrating how attention can steer dynamic grouping and enhance object-level representations. The third model employs a recurrent complex-valued architecture (CV-RNN), where synchrony is maintained over time to support the integration and tracking of dynamically changing objects. Each of these models improves generalization, robustness to clutter and occlusion, and demonstrates more human-like behavior compared to traditional architectures. In addition to computational evaluations, this work examines shared temporal variance (STV) -- a proxy for neural synchrony -- in biological neural recordings from primate inferior temporal (IT) cortex. This proxy enables direct comparisons between neural synchrony in biological systems and artificial models. Empirical analyses reveal that STV captures object category and behavioral information independently of firing rates in biological systems, but not in dynamic artificial models, highlighting the need for further work to align ANN temporal dynamics with those of the brain. In conclusion, this thesis presents empirical evidence supporting neural synchrony as a functionally advantageous mechanism for visual binding, demonstrating improved object representation, robustness, and human-like generalization in artificial neural networks. Furthermore, by bridging computational modeling with biological neural data, it advances our understanding of synchrony as a foundational mechanism underlying visual perception.

![Binding](/images/fig_binding.jpg)
